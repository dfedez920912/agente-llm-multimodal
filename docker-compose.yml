# docker-compose.yml
version: '3.8'

services:
  llm-agent:
    build: .
    restart: always
    environment:
      # Carga las variables de los modelos y la API_KEY del archivo .env
      - API_KEY=${API_KEY}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME}
      - VL_LLM_MODEL_NAME=${VL_LLM_MODEL_NAME}
      - ASR_MODEL_NAME=${ASR_MODEL_NAME}
    ports:
      - "8000:8000"
    volumes:
      # Opcional: Monta un volumen para cachear los modelos descargados y evitar descargas repetidas
      - model-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            # Habilita el acceso a la GPU. Se debe tener instalado Docker-NVIDIA-Toolkit.
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  model-cache:
    driver: local
